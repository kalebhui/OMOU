{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvcP5KEEM_X",
        "outputId": "5bac5253-913b-4b82-cee3-9a222d0dbeec"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 217kB/s \n",
            "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 40.3MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=9447581048c5e4336fbf2b8e42f5a66d09fc991f41616946e274a79a967c9c21\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: pydantic, typer, smart-open, pathy, catalogue, srsly, thinc, spacy-legacy, spacy\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "2021-05-13 02:44:47.332056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 226kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGfTigKXoxLF"
      },
      "source": [
        "import torch, torchtext\n",
        "from torch import nn, optim, functional as F\n",
        "import pandas as pd, csv\n",
        "import pdb\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VRctGFhE6Pf",
        "outputId": "2f083b7d-cf0e-400e-e124-85f18497798f"
      },
      "source": [
        "!unzip tracks.zip"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tracks.zip\n",
            "  inflating: tracks.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbeIbgagBbvB",
        "outputId": "657d17ce-5149-46c7-fff9-265cdd74db61"
      },
      "source": [
        "!wget -O text.csv https://www.dropbox.com/s/iulhdbo1yc8farq/Emotion_final.csv?dl=0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-13 02:44:54--  https://www.dropbox.com/s/iulhdbo1yc8farq/Emotion_final.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/iulhdbo1yc8farq/Emotion_final.csv [following]\n",
            "--2021-05-13 02:44:54--  https://www.dropbox.com/s/raw/iulhdbo1yc8farq/Emotion_final.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccfe36f373ed193a41947007440.dl.dropboxusercontent.com/cd/0/inline/BOb76fK9vTWskyMeI9XjMIxtwNe7pl6QjIL362AJGE3bioGbXd0Os1JqMdy44N7CaVrmeuhbahAKfROdjm3wSOWvmDMYII2U8OVYMbM9wm_y_0jrhgVYOWYHBz11ss2PaPCF-aHbDztVwLXhoPo0htM_/file# [following]\n",
            "--2021-05-13 02:44:55--  https://uccfe36f373ed193a41947007440.dl.dropboxusercontent.com/cd/0/inline/BOb76fK9vTWskyMeI9XjMIxtwNe7pl6QjIL362AJGE3bioGbXd0Os1JqMdy44N7CaVrmeuhbahAKfROdjm3wSOWvmDMYII2U8OVYMbM9wm_y_0jrhgVYOWYHBz11ss2PaPCF-aHbDztVwLXhoPo0htM_/file\n",
            "Resolving uccfe36f373ed193a41947007440.dl.dropboxusercontent.com (uccfe36f373ed193a41947007440.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to uccfe36f373ed193a41947007440.dl.dropboxusercontent.com (uccfe36f373ed193a41947007440.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2377315 (2.3M) [text/plain]\n",
            "Saving to: ‘text.csv’\n",
            "\n",
            "text.csv            100%[===================>]   2.27M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-05-13 02:44:55 (155 MB/s) - ‘text.csv’ saved [2377315/2377315]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vQQmLY7BdKP"
      },
      "source": [
        "text = pd.read_csv('/content/text.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uVU8tQBe-T"
      },
      "source": [
        "sentiment = ['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUe1xL55v_Fl"
      },
      "source": [
        "def remove_punctuation(text): #function for removing punctuation\n",
        "    import string \n",
        "    translator = str.maketrans('', '', string.punctuation) #replace the punctuations with no space\n",
        "    return text.translate(translator)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-zUfxFR8qPw"
      },
      "source": [
        "class Sentences(torch.utils.data.Dataset):\n",
        "    def __init__(self, fn):\n",
        "        lengths = []\n",
        "        convert = { u: n for n, u in enumerate(fn['Emotion'].unique()) }\n",
        "        fn['Emotion'] = fn['Emotion'].apply(lambda u: convert[u])               # 12 unique words should be assigned integers starting from 0\n",
        "        tokenizer = torchtext.data.utils.get_tokenizer('spacy', 'en_core_web_sm')# tokenizer using spaCy\n",
        "        for i in range(len(fn['Text'])):\n",
        "          lengths.append(len(tokenizer(fn['Text'].iat[i].strip())))                   # store the number of tokens in each sentence to beused in get item\n",
        "        string = ' '.join([fn['Text'].iat[i].strip() \n",
        "                           for i in range(len(fn['Text']))])                  # combine everything into one single string\n",
        "        toks = tokenizer(string)                                                # tokenize the single string\n",
        "\n",
        "        self.vocab = torchtext.vocab.build_vocab_from_iterator([toks])\n",
        "        self.sentiment = fn['Emotion'].values\n",
        "        self.text = fn['Text'].values\n",
        "        self.length = lengths\n",
        "        self.toks = torch.LongTensor([self.vocab[tok] for tok in toks])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.length)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        sum = 0\n",
        "        for x in range(i):\n",
        "          sum += self.length[x]\n",
        "        return (self.sentiment[i], self.toks[sum: sum + self.length[i]])          # return the sentiment and related tokns for a specific tweet\n",
        "    \n",
        "    def input_to_tensor(self, string):\n",
        "        string = remove_punctuation(string)\n",
        "        in_toks = string.split(\" \")\n",
        "        return torch.LongTensor([self.vocab[i] for i in in_toks])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhGpWcaQ8vtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f7c395-d0eb-4455-a9ab-056e2414b272"
      },
      "source": [
        "ds_full = Sentences(text)\n",
        "n_train = int(0.8 * len(ds_full))\n",
        "n_test = len(ds_full) - n_train\n",
        "rng = torch.Generator().manual_seed(291)\n",
        "ds_train, ds_test = torch.utils.data.random_split(ds_full, [n_train, n_test], rng)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1lines [00:00, 23.58lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWGBLBUUrgj0"
      },
      "source": [
        "class SentenceModel(nn.Module):                                                 # takes in a sentence, and outputs predicted sentiment\n",
        "      def __init__(self, vocab_size, embedding_dim, lstm_dim, \n",
        "                   n_cats, n_layers = 2, drop_prob = 0.5):\n",
        "        super().__init__()                                                      #constructor for parent class\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)          #use word embeddings \n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, lstm_dim, n_layers,\n",
        "                                  dropout=drop_prob, batch_first=True)          #LSTM layer\n",
        "        self.linear = nn.Linear(lstm_dim, n_cats)\n",
        "        nn.init.xavier_uniform_(self.embedding.weight.data)\n",
        "        nn.init.xavier_uniform_(self.linear.weight.data)\n",
        "        \n",
        "      def forward(self, text):\n",
        "        emb = self.embedding(text)\n",
        "        lstm_out, _ = self.lstm(emb)\n",
        "        out = self.linear(lstm_out)\n",
        "        return torch.mean(out, dim=1)                                           # certain dimensions required so take mean to reduce them down"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heCZ0zY5DwLM"
      },
      "source": [
        "#First locate tracks.zip and paste the file path in the unzip below"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2DDbaic16gG"
      },
      "source": [
        "# **DATASET CODE HERE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rLxlZKx1_HD"
      },
      "source": [
        "upload -> sentence_model_state_dict (the saved fully trained model) \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3oeoLiW4nd"
      },
      "source": [
        "model = SentenceModel(len(ds_full.vocab)+2, 64, 64, len(text.Emotion.unique()))\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device);\n",
        "crit = nn.CrossEntropyLoss().to(device)\n",
        "opt = optim.SGD(model.parameters(), lr=0.1)\n",
        "sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSG7KmZ2_ulS",
        "outputId": "17b16b13-ab49-4929-fca8-c5b1b2dbce0c"
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "model.load_state_dict(torch.load(\"/content/sentence_model_state_dict.pth\"))\n",
        "model.eval()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceModel(\n",
              "  (embedding): Embedding(19910, 64)\n",
              "  (lstm): LSTM(64, 64, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG_wCnoCCNJC"
      },
      "source": [
        "ldr = torch.utils.data.DataLoader(ds_test) "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qITlFNCzLP4s"
      },
      "source": [
        "def get_weights(tensor=None, model=None): #tensor should have shape ([x, y, z, ...]) (1 dim), NOT ([[x, y, z, ...]]), the function itself unsqueezes the input tensor for you\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  device = torch.device('cuda:0')\n",
        "  model.to(device)\n",
        "  m = nn.ReLU()\n",
        "  s = nn.Softmax(dim=1)\n",
        "  with torch.no_grad():\n",
        "    update_tensor = model(tensor.to(device))\n",
        "    print(update_tensor)\n",
        "    relud_logged = torch.log(m(update_tensor))\n",
        "    print(relud_logged)\n",
        "    print(\"Tensor converted to text: \" + ' '.join([ds_full.vocab.itos[x] for x in tensor.squeeze()]))\n",
        "    return s(relud_logged).squeeze()\n",
        "  \n",
        "  # this function calculates the appropriate probability distribution for every track based on input \"tensor\" and our model"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lgm5scLSoFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4bd715df-7ccf-4a7c-ce60-24af06458a93"
      },
      "source": [
        "tracks = pd.read_csv('/content/tracks.csv')\n",
        "tracks.drop(inplace=True, columns=['duration_ms','key', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo', 'time_signature', 'loudness'])\n",
        "tracks.sort_values(by=['popularity'], ascending=False)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>popularity</th>\n",
              "      <th>explicit</th>\n",
              "      <th>artists</th>\n",
              "      <th>id_artists</th>\n",
              "      <th>release_date</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93802</th>\n",
              "      <td>4iJyoBOLtHqaGxP12qzhQI</td>\n",
              "      <td>Peaches (feat. Daniel Caesar &amp; Giveon)</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>['Justin Bieber', 'Daniel Caesar', 'Giveon']</td>\n",
              "      <td>['1uNFoZAHBGtllmzznpCI3s', '20wkVLutqVOYrc0kxF...</td>\n",
              "      <td>2021-03-19</td>\n",
              "      <td>0.677</td>\n",
              "      <td>0.6960</td>\n",
              "      <td>0.464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93803</th>\n",
              "      <td>7lPN2DXiMsVn7XUKtOW1CS</td>\n",
              "      <td>drivers license</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>['Olivia Rodrigo']</td>\n",
              "      <td>['1McMsnEElThX1knmY4oliG']</td>\n",
              "      <td>2021-01-08</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.4360</td>\n",
              "      <td>0.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93804</th>\n",
              "      <td>3Ofmpyhv5UAQ70mENzB277</td>\n",
              "      <td>Astronaut In The Ocean</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "      <td>['Masked Wolf']</td>\n",
              "      <td>['1uU7g3DNSbsu0QjSEqZtEd']</td>\n",
              "      <td>2021-01-06</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.6950</td>\n",
              "      <td>0.472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92810</th>\n",
              "      <td>5QO79kh1waicV47BqGRL3g</td>\n",
              "      <td>Save Your Tears</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>['The Weeknd']</td>\n",
              "      <td>['1Xyo4u8uXC1ZmMpatF05PJ']</td>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.8260</td>\n",
              "      <td>0.644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92811</th>\n",
              "      <td>6tDDoYIxWvMLTdKpjFkc1B</td>\n",
              "      <td>telepatía</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "      <td>['Kali Uchis']</td>\n",
              "      <td>['1U1el3k54VvEUzo3ybLPlM']</td>\n",
              "      <td>2020-12-04</td>\n",
              "      <td>0.653</td>\n",
              "      <td>0.5240</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23410</th>\n",
              "      <td>0sniGbmm1sjg51BxO6AHD4</td>\n",
              "      <td>O Pardesi Musafir</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['Suraiya', 'Lata Mangeshkar']</td>\n",
              "      <td>['71lk7UDkZK1mabUE6LCASW', '61JrslREXq98hurYL2...</td>\n",
              "      <td>1949-01-01</td>\n",
              "      <td>0.682</td>\n",
              "      <td>0.3050</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23409</th>\n",
              "      <td>0sk8KA96i9MIU8St2nmbIx</td>\n",
              "      <td>Mere Dil Mein Aao Aur Bas Jao</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['Suraiya']</td>\n",
              "      <td>['71lk7UDkZK1mabUE6LCASW']</td>\n",
              "      <td>1949-01-01</td>\n",
              "      <td>0.527</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23408</th>\n",
              "      <td>0sdkzsc3WtZIrSi1nNyl7v</td>\n",
              "      <td>Diversions, Op. 21: Variation 9, Toccata I</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['Benjamin Britten', 'Leon Fleisher', 'Seiji O...</td>\n",
              "      <td>['7MJ1pB5d6Vjmzep2zQlorn', '6ncNdxBc8zVWMOF7nJ...</td>\n",
              "      <td>1949</td>\n",
              "      <td>0.441</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23407</th>\n",
              "      <td>0s6h3lMdJsWkpUAW6xC7m3</td>\n",
              "      <td>John Henry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['Lead Belly']</td>\n",
              "      <td>['3Ovf2lytXSXWFM2cwsJACC']</td>\n",
              "      <td>1949</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444118</th>\n",
              "      <td>4Jb8iDtQk8QgFFMHApIrgK</td>\n",
              "      <td>Kevin Barry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['The Clancy Brothers', 'Tommy Makem', \"Paddy'...</td>\n",
              "      <td>['4qWTqOdDnH56Qak9UjmpKz', '3oehGAh6rLM6LFdzM7...</td>\n",
              "      <td>2015-06-29</td>\n",
              "      <td>0.431</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>586672 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            id  ... valence\n",
              "93802   4iJyoBOLtHqaGxP12qzhQI  ...   0.464\n",
              "93803   7lPN2DXiMsVn7XUKtOW1CS  ...   0.132\n",
              "93804   3Ofmpyhv5UAQ70mENzB277  ...   0.472\n",
              "92810   5QO79kh1waicV47BqGRL3g  ...   0.644\n",
              "92811   6tDDoYIxWvMLTdKpjFkc1B  ...   0.553\n",
              "...                        ...  ...     ...\n",
              "23410   0sniGbmm1sjg51BxO6AHD4  ...   0.910\n",
              "23409   0sk8KA96i9MIU8St2nmbIx  ...   0.688\n",
              "23408   0sdkzsc3WtZIrSi1nNyl7v  ...   0.528\n",
              "23407   0s6h3lMdJsWkpUAW6xC7m3  ...   0.732\n",
              "444118  4Jb8iDtQk8QgFFMHApIrgK  ...   0.391\n",
              "\n",
              "[586672 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHyGD064J7h3"
      },
      "source": [
        "sentiment = ['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yknXmQ8LaIo7"
      },
      "source": [
        "# list_scores = []\n",
        "# in = ('sadness', 'anger', 'love', 'surprise', 'fear', 'happy')\n",
        "# for **track** in list of tracks over 65 popularity:\n",
        "#    score = POPULARITY_WEIGHT * (track.popularity / 100) + in.sadness * (1 - track.valence) + in.anger * track.energy + in.love * (mean(track.energy + track.dancability)) + in.surprise * (1 - track.energy) + in.fear * valence + in.happy * (mean(track.danceability + track.energy))\n",
        "#    list_scores.append(score)\n",
        "\n",
        "# np.random.choice(tracks, list_scores)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx3TpxS6Ypms"
      },
      "source": [
        "new_df = tracks[tracks.popularity >=65]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3degcmPhlzFj"
      },
      "source": [
        "def normalize(p): # makes sure the distribution probability list adds to 1\n",
        "    if sum(p) != 1.0:\n",
        "        p = np.asarray(p)*(1.0/sum(p))\n",
        "    return p"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtwG6hXBdWjh",
        "outputId": "3691bd23-be6b-462d-995a-241ffa77589c"
      },
      "source": [
        "#user input is x -> we have to convert user input string into tensor \"x\"\n",
        "#so input would be \"input = get_weights(x, model)\"\n",
        "\n",
        "POPULARITY_WEIGHT = 1.5 # can be changed \n",
        "NUM_TRACK_OPTIONS = 25 # can be changed\n",
        "\n",
        "input_string = \"i'm having a great day today!\"\n",
        "id_tracks = new_df[\"id\"].values.tolist()\n",
        "scores_id = []\n",
        "seq = ds_full.input_to_tensor(input_string)\n",
        "input = get_weights(seq, model)\n",
        "for track in new_df.itertuples(index=False):\n",
        "    score = POPULARITY_WEIGHT*(track.popularity/100) + input[0].item()*(1-track.valence) + input[1].item()*track.energy + input[2].item()*((track.energy + track.danceability)/2) + input[3].item()*(1-track.energy) + input[4].item()*track.valence + input[5].item()*((track.danceability + track.energy)/2)\n",
        "    scores_id.append([score, track.id])\n",
        "\n",
        "distribution = []\n",
        "top_track_ids = []\n",
        "s = sorted(scores_id, reverse=True)\n",
        "s = s[0:NUM_TRACK_OPTIONS]\n",
        "\n",
        "for score, id in s:\n",
        "  distribution.append(score)\n",
        "  top_track_ids.append(id)\n",
        "print(\"\\n\")\n",
        "id = np.random.choice(top_track_ids, p=normalize(distribution)) # picks a random track across a distribution generated by the scores\n",
        "print(\"Distribution: {0}\".format(input))\n",
        "print(\"TRACK LINK: https://open.spotify.com/track/\" + id)\n",
        "actual_track = new_df[new_df['id']==id]\n",
        "print(actual_track)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0117,  2.0134, -2.9310,  1.4684, -0.3427, -1.9823]],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0116, 0.6998,   -inf, 0.3841,   -inf,   -inf]], device='cuda:0')\n",
            "Tensor converted to text: <unk> having a great day today\n",
            "\n",
            "\n",
            "Distribution: tensor([0.2251, 0.4481, 0.0000, 0.3268, 0.0000, 0.0000], device='cuda:0')\n",
            "TRACK LINK: https://open.spotify.com/track/65OVbaJR5O1RmwOQx0875b\n",
            "                           id  ... valence\n",
            "93823  65OVbaJR5O1RmwOQx0875b  ...     0.1\n",
            "\n",
            "[1 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}