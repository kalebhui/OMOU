{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anime+podcast.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqBKCyl37wn3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVwPkuBC846w"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOGAzmAT85pL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37uLqlOI7-sM",
        "outputId": "aef4ec28-1675-48be-c02c-ca2097fbfa49"
      },
      "source": [
        "pip install np_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.7/dist-packages (0.5.12.1)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgPRW9Iv7_Po",
        "outputId": "a3855b0b-0234-4958-cefb-06206599d217"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twa4nBWv8r49"
      },
      "source": [
        "podcast_model = keras.models.load_model('/content/drive/MyDrive/podcast_model.h5')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEfsQU08xic"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "MAX_SEQUENCE_LENGTH = 250"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sPkfuVH80Xt",
        "outputId": "6068d3e7-6b9f-4b75-c365-ccb4d9f4d508"
      },
      "source": [
        "new_summary  = [' NOOOOOOOOO ']\n",
        "seq = tokenizer.texts_to_sequences(new_summary )\n",
        "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "pred = podcast_model.predict(padded)\n",
        "labels = ['Literature', 'Business News', 'Comedy' ,'History', 'Places & Travel']\n",
        "print(pred, labels[np.argmax(pred)])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2989716  0.22055312 0.14677978 0.21166296 0.12203252]] Literature\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ls20HT8Kzj"
      },
      "source": [
        "anime_model = keras.models.load_model('/content/drive/My Drive/anime_model.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmNfNxBV8NWz"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "MAX_SEQUENCE_LENGTH = 250"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXjCadKI8aEX",
        "outputId": "1eae8b35-7791-49d1-f609-5937c420eca7"
      },
      "source": [
        "new_summary  = ['lets go out and have something cause i am hungry']\n",
        "seq = tokenizer.texts_to_sequences(new_summary )\n",
        "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "pred = anime_model.predict(padded)\n",
        "labels = ['Music', 'Comedy', 'Fantasy', 'Drama', 'Dementia']\n",
        "print(pred, labels[np.argmax(pred)])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.406623   0.19988005 0.11588804 0.14623362 0.13137539]] Music\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}